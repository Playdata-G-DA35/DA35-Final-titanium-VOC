{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 숫자 추출 함수\n",
    "-> 구매수 or 조회 수 구할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 문자열에서 숫자 추출하는 함수\n",
    "def extract_number(value):\n",
    "    match = re.search(r'(\\d+\\.?\\d*)', str(value))\n",
    "    number = float(match.group(1)) if match else 0\n",
    "    return number\n",
    "\n",
    "# 만, 천 숫자로 변환하는 함수\n",
    "def convert_to_int(value):\n",
    "    value = str(value)\n",
    "    number = extract_number(value)\n",
    "\n",
    "    if '만' in value:\n",
    "        return round(number * 10000)\n",
    "    elif '천' in value:\n",
    "        return round(number * 1000)\n",
    "    \n",
    "    return round(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행 처리 함수(구매수 or 조회수, 연령, 성별)\n",
    "-> 행에 있는 데이터들을 구매수, 연령, 성별 데이터를 추출하여 컬럼에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구매현황 처리\n",
    "def process_purchase_row(row):\n",
    "    if pd.isna(row):\n",
    "        print(\"구매현황 데이터가 NaN입니다.\")\n",
    "        return pd.Series({'구매수': 0, '구매_~18세': 0, '구매_19~23세': 0, '구매_24~28세': 0,\n",
    "                           '구매_29~33세': 0, '구매_34~39세': 0, '구매_40세~': 0, '구매_남성': 0, '구매_여성': 0})\n",
    "\n",
    "    if not isinstance(row, str):\n",
    "        print(f\"Unexpected data type in 구매현황: {type(row)}\")\n",
    "        return pd.Series({'구매수': 0, '구매_~18세': 0, '구매_19~23세': 0, '구매_24~28세': 0,\n",
    "                           '구매_29~33세': 0, '구매_34~39세': 0, '구매_40세~': 0, '구매_남성': 0, '구매_여성': 0})\n",
    "    \n",
    "    data = row.split('\\n')\n",
    "    \n",
    "    try:\n",
    "        purchase_count = convert_to_int(data[0].split(' ')[2])\n",
    "    except (IndexError, ValueError):\n",
    "        print(f\"구매현황 데이터 형식이 잘못되었습니다: {row}\")\n",
    "        return pd.Series({'구매수': 0, '구매_~18세': 0, '구매_19~23세': 0, '구매_24~28세': 0,\n",
    "                           '구매_29~33세': 0, '구매_34~39세': 0, '구매_40세~': 0, '구매_남성': 0, '구매_여성': 0})\n",
    "    \n",
    "    result = {'구매수': purchase_count}\n",
    "    \n",
    "    age_groups = ['~18세', '19~23세', '24~28세', '29~33세', '34~39세', '40세~']\n",
    "    genders = ['남성', '여성']\n",
    "    \n",
    "    # 연령 데이터 처리\n",
    "    try:\n",
    "        age_start = data.index('연령') + 8\n",
    "        age_data = data[age_start:age_start + 12:2]\n",
    "        for i, age in enumerate(age_groups):\n",
    "            result[f'구매_{age}'] = round(extract_number(age_data[i]) * purchase_count / 100)\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"연령 데이터를 찾거나 처리하는 데 오류가 발생했습니다.\")\n",
    "        for age in age_groups:\n",
    "            result[f'구매_{age}'] = 0\n",
    "    \n",
    "    # 성별 데이터 처리\n",
    "    try:\n",
    "        gender_start = data.index('성별') + 4\n",
    "        gender_data = data[gender_start:gender_start + 3:2]\n",
    "        for i, gender in enumerate(genders):\n",
    "            percentage = extract_number(gender_data[i].split()[-1])\n",
    "            result[f'구매_{gender}'] = round(percentage * purchase_count / 100)\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"성별 데이터를 찾거나 처리하는 데 오류가 발생했습니다.\")\n",
    "        for gender in genders:\n",
    "            result[f'구매_{gender}'] = 0\n",
    "    \n",
    "    return pd.Series(result)\n",
    "\n",
    "# 조회현황 처리\n",
    "def process_view_row(row):\n",
    "    if pd.isna(row):\n",
    "        print(\"조회현황 데이터가 NaN입니다.\")\n",
    "        return pd.Series({'조회수': 0, '조회_~18세': 0, '조회_19~23세': 0, '조회_24~28세': 0,\n",
    "                           '조회_29~33세': 0, '조회_34~39세': 0, '조회_40세~': 0, '조회_남성': 0, '조회_여성': 0})\n",
    "\n",
    "    if not isinstance(row, str):\n",
    "        print(f\"Unexpected data type in 조회현황: {type(row)}\")\n",
    "        return pd.Series({'조회수': 0, '조회_~18세': 0, '조회_19~23세': 0, '조회_24~28세': 0,\n",
    "                           '조회_29~33세': 0, '조회_34~39세': 0, '조회_40세~': 0, '조회_남성': 0, '조회_여성': 0})\n",
    "    \n",
    "    data = row.split('\\n')\n",
    "    \n",
    "    try:\n",
    "        view_count = convert_to_int(data[0].split(' ')[2])\n",
    "    except (IndexError, ValueError):\n",
    "        print(f\"조회현황 데이터 형식이 잘못되었습니다: {row}\")\n",
    "        return pd.Series({'조회수': 0, '조회_~18세': 0, '조회_19~23세': 0, '조회_24~28세': 0,\n",
    "                           '조회_29~33세': 0, '조회_34~39세': 0, '조회_40세~': 0, '조회_남성': 0, '조회_여성': 0})\n",
    "    \n",
    "    result = {'조회수': view_count}\n",
    "    \n",
    "    age_groups = ['~18세', '19~23세', '24~28세', '29~33세', '34~39세', '40세~']\n",
    "    genders = ['남성', '여성']\n",
    "    \n",
    "    # 연령 데이터 처리\n",
    "    try:\n",
    "        age_start = data.index('연령') + 8\n",
    "        age_data = data[age_start:age_start + 12:2]\n",
    "        for i, age in enumerate(age_groups):\n",
    "            result[f'조회_{age}'] = round(extract_number(age_data[i]) * view_count / 100)\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"연령 데이터를 찾거나 처리하는 데 오류가 발생했습니다.\")\n",
    "        for age in age_groups:\n",
    "            result[f'조회_{age}'] = 0\n",
    "    \n",
    "    # 성별 데이터 처리\n",
    "    try:\n",
    "        gender_start = data.index('성별') + 4\n",
    "        gender_data = data[gender_start:gender_start + 3:2]\n",
    "        for i, gender in enumerate(genders):\n",
    "            percentage = extract_number(gender_data[i].split()[-1])\n",
    "            result[f'조회_{gender}'] = round(percentage * view_count / 100)\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"성별 데이터를 찾거나 처리하는 데 오류가 발생했습니다.\")\n",
    "        for gender in genders:\n",
    "            result[f'조회_{gender}'] = 0\n",
    "    \n",
    "    return pd.Series(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가격 처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(price):\n",
    "    cleaned_price = price.split('~')[-1].strip().replace(',', '').replace('원', '')\n",
    "    return round(float(cleaned_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가격대 구분 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가격대 구분 함수 정의\n",
    "def categorize_price(price):\n",
    "    if price >= 10000 and price < 20000:\n",
    "        return '1~2만원대'\n",
    "    elif price >= 30000 and price < 40000:\n",
    "        return '3~4만원대'\n",
    "    elif price >= 50000:\n",
    "        return '5만원대 이상'\n",
    "    else:\n",
    "        return '기타'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카테고리 분리코드\n",
    "-> 상위 / 하위카테고리 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_category(category):\n",
    "    # ' > ' 기준으로 카테고리를 나누기\n",
    "    category_parts = category.split(' > ')\n",
    "    \n",
    "    # 분리된 카테고리 리스트가 3개인 경우\n",
    "    if len(category_parts) == 3:\n",
    "        # ' (브랜드명)' 부분을 제거하고 분리\n",
    "        lower_parts = category_parts[2].split(' (')\n",
    "        upper_category = category_parts[1].strip()\n",
    "        sub_category = lower_parts[0].strip()\n",
    "        brand_name = lower_parts[1][:-1].strip() if len(lower_parts) > 1 else None\n",
    "        \n",
    "        # 분리된 값을 반환\n",
    "        return pd.Series([sub_category, '', brand_name])\n",
    "    \n",
    "    # 분리된 카테고리 리스트가 2개인 경우\n",
    "    elif len(category_parts) == 2:\n",
    "        # ' (브랜드명)' 부분을 제거하고 분리\n",
    "        lower_parts = category_parts[1].split(' (')\n",
    "        sub_category = lower_parts[0].strip()\n",
    "        brand_name = lower_parts[1][:-1].strip() if len(lower_parts) > 1 else None\n",
    "        \n",
    "        # 분리된 값을 반환\n",
    "        return pd.Series([category_parts[0].strip(), sub_category, brand_name])\n",
    "    \n",
    "    # 분리된 카테고리 리스트가 1개 이하인 경우\n",
    "    else:\n",
    "        return pd.Series([None, None, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리뷰 태그"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def split_review_tags(df):\n",
    "    # 태그 카테고리 정의\n",
    "    tag_categories = ['사이즈', '밝기', '색감', '두께감', '보온성', '무게감', '배송', '포장']\n",
    "    \n",
    "    # 카테고리별 열 이름을 위한 리스트\n",
    "    tag_columns = [f'리뷰태그_{category}' for category in tag_categories]\n",
    "    \n",
    "    # 결과를 담을 딕셔너리\n",
    "    def process_tags(tags):\n",
    "        # 모든 카테고리에 대해 초기화\n",
    "        result = {f'리뷰태그_{category}': None for category in tag_categories}\n",
    "        \n",
    "        if pd.isna(tags):  # NaN 처리\n",
    "            return pd.Series(result)\n",
    "        \n",
    "        # 문자열 리스트를 실제 리스트로 변환\n",
    "        try:\n",
    "            tags_list = ast.literal_eval(tags)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return pd.Series(result)\n",
    "        \n",
    "        # 각 태그를 카테고리별로 나누어 처리\n",
    "        for tag in tags_list:\n",
    "            for category in tag_categories:\n",
    "                if tag.startswith(category):\n",
    "                    if '보통이에요' in tag:\n",
    "                        result[f'리뷰태그_{category}'] = f'{category} 보통이에요'\n",
    "                    else:\n",
    "                        if result[f'리뷰태그_{category}'] is None:\n",
    "                            result[f'리뷰태그_{category}'] = tag\n",
    "                    break\n",
    "        \n",
    "        return pd.Series(result)\n",
    "    \n",
    "    # '리뷰태그' 열을 카테고리별로 처리하고 새로운 열로 추가\n",
    "    review_tags_df = df['리뷰태그'].apply(process_tags)\n",
    "    \n",
    "    # 원본 데이터프레임에 병합\n",
    "    df = pd.concat([df, review_tags_df], axis=1)\n",
    "    \n",
    "    # 기존 '리뷰태그' 열 삭제\n",
    "    df.drop(columns=['리뷰태그'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상품 ID & 리뷰 ID 추가 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def plus_product_ID(df):\n",
    "    # 상품명별로 그룹화하고 각 그룹에 대해 고유한 ID 생성\n",
    "    df['Product ID'] = df.groupby('상품명').ngroup().astype(str).str.zfill(5)\n",
    "    \n",
    "    # 'product_' 접두사 추가\n",
    "    df['Product ID'] = 'product_' + df['Product ID']\n",
    "\n",
    "def plus_review_ID(df):\n",
    "    # 상품명별로 그룹화하고 각 그룹에 대해 고유한 ID 생성\n",
    "    df['Review ID'] = df.groupby('리뷰').ngroup().astype(str).str.zfill(5)\n",
    "    \n",
    "    # 'product_' 접두사 추가\n",
    "    df['Review ID'] = 'review_' + df['Review ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실행 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구매현황 데이터가 NaN입니다.\n",
      "구매현황 데이터가 NaN입니다.\n",
      "구매현황 데이터가 NaN입니다.\n",
      "구매현황 데이터가 NaN입니다.\n",
      "구매현황 데이터가 NaN입니다.\n",
      "구매현황 데이터가 NaN입니다.\n",
      "구매현황 데이터가 NaN입니다.\n",
      "구매현황 데이터가 NaN입니다.\n",
      "구매현황 데이터가 NaN입니다.\n",
      "구매현황 데이터가 NaN입니다.\n",
      "조회현황 데이터가 NaN입니다.\n",
      "조회현황 데이터가 NaN입니다.\n",
      "조회현황 데이터가 NaN입니다.\n",
      "조회현황 데이터가 NaN입니다.\n",
      "조회현황 데이터가 NaN입니다.\n",
      "조회현황 데이터가 NaN입니다.\n",
      "조회현황 데이터가 NaN입니다.\n",
      "조회현황 데이터가 NaN입니다.\n",
      "조회현황 데이터가 NaN입니다.\n",
      "조회현황 데이터가 NaN입니다.\n",
      "변환된 데이터가 musinsa_crawling_dataset\\musinsa_crawling_columns_preprocessing_dataset.csv 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 파일 경로 정의\n",
    "file_path = 'musinsa_crawling_dataset/musinsa_crawling_concat_dataset.csv'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 데이터 전처리\n",
    "df['상품좋아요수'] = df['상품좋아요수'].str.replace(',', '', regex=False).astype('int64')\n",
    "df.drop(columns=['배송'], inplace=True)\n",
    "df['작성일'] = pd.to_datetime(df['작성일'], errors='coerce').dt.strftime('%Y%m%d').astype('int64')\n",
    "df['성별'] = df['성별'].map({'남성': 1, '여성': 0})\n",
    "\n",
    "# 구매현황 및 조회현황 컬럼 처리\n",
    "purchase_columns = df['구매현황'].apply(process_purchase_row)\n",
    "view_columns = df['조회현황'].apply(process_view_row)\n",
    "\n",
    "df = pd.concat([df, purchase_columns, view_columns], axis=1)\n",
    "df.drop(columns=['구매현황', '조회현황'], inplace=True)\n",
    "\n",
    "# 가격 데이터 정리\n",
    "df['상품가격'] = df['상품가격'].apply(clean_price).astype('int64')\n",
    "\n",
    "# 가격대 컬럼 추가\n",
    "df['가격대'] = df['상품가격'].apply(categorize_price)\n",
    "\n",
    "# 카테고리 분리\n",
    "df[['상위 카테고리', '하위 카테고리', '브랜드명']] = df['카테고리'].apply(split_category)\n",
    "\n",
    "# 리뷰태그 분리\n",
    "df = split_review_tags(df)\n",
    "\n",
    "# Product ID 추가\n",
    "plus_product_ID(df)\n",
    "\n",
    "# Review ID 추가\n",
    "plus_review_ID(df)\n",
    "\n",
    "# 변환된 데이터를 새로운 CSV 파일로 저장\n",
    "output_dir = 'musinsa_crawling_dataset'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'musinsa_crawling_columns_preprocessing_dataset.csv')\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"변환된 데이터가 {output_path} 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼이름 영어 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환된 데이터가 musinsa_crawling_dataset\\musinsa_crawling_columns_preprocessing_dataset.csv 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# '카테고리' 열 삭제\n",
    "df.drop(columns=['카테고리'], inplace=True)\n",
    "\n",
    "# 컬럼 이름 변경\n",
    "df.rename(columns={\n",
    "    '상품명': 'product',\n",
    "    '상품좋아요수': 'product_like',\n",
    "    '상품가격': 'product_price',\n",
    "    '가격대': 'price_range',\n",
    "    '상품태그': 'product_tag',\n",
    "    '리뷰': 'review',\n",
    "    '작성일': 'date',\n",
    "    '평점': 'grade',\n",
    "    '사이즈': 'size',\n",
    "    '성별': 'sex',\n",
    "    '키': 'height',\n",
    "    '몸무게': 'weight',\n",
    "    '누적판매량': 'cumulative_sales_volume',\n",
    "    '도움돼요': 'helpful',\n",
    "    '스타일 좋아요': 'style_like',\n",
    "    '구매수': 'purchases',\n",
    "    '구매_~18세': 'purchases_18',\n",
    "    '구매_19~23세': 'purchases_19_23',\n",
    "    '구매_24~28세': 'purchases_24_28',\n",
    "    '구매_29~33세': 'purchases_29_33',\n",
    "    '구매_34~39세': 'purchases_34_39',\n",
    "    '구매_40세~': 'purchases_40',\n",
    "    '구매_남성': 'purchases_male',\n",
    "    '구매_여성': 'purchases_female',\n",
    "    '조회수': 'views',\n",
    "    '조회_~18세': 'views_18',\n",
    "    '조회_19~23세': 'views_19_23',\n",
    "    '조회_24~28세': 'views_24_28',\n",
    "    '조회_29~33세': 'views_29_33',\n",
    "    '조회_34~39세': 'views_34_39',\n",
    "    '조회_40세~': 'views_40',\n",
    "    '조회_남성': 'views_male',\n",
    "    '조회_여성': 'views_female',\n",
    "    '상위 카테고리': 'category',\n",
    "    '하위 카테고리': 'subcategory',\n",
    "    '브랜드명': 'brand',\n",
    "    '리뷰태그_사이즈': 'reviewtag_size',\n",
    "    '리뷰태그_밝기': 'reviewtag_brightness',\n",
    "    '리뷰태그_색감': 'reviewtag_color',\n",
    "    '리뷰태그_두께감': 'reviewtag_thickness',\n",
    "    '리뷰태그_보온성': 'reviewtag_warmth',\n",
    "    '리뷰태그_무게감': 'reviewtag_weight',\n",
    "    '리뷰태그_배송': 'reviewtag_delivery',\n",
    "    '리뷰태그_포장': 'reviewtag_packaging',\n",
    "    'Product ID': 'product_ID',\n",
    "    'Review ID': 'review_ID'\n",
    "}, inplace=True)\n",
    "\n",
    "# 변환된 데이터를 새로운 CSV 파일로 저장\n",
    "output_dir = 'musinsa_crawling_dataset'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'musinsa_crawling_columns_preprocessing_dataset.csv')\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"변환된 데이터가 {output_path} 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼 순서 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 순서 재정렬\n",
    "desired_order = [\n",
    "    'index', 'brand', 'category', 'subcategory', 'product', 'product_ID', 'product_like', 'product_price', 'price_range',\n",
    "    'product_tag', 'cumulative_sales_volume', 'purchases', 'purchases_18', 'purchases_19_23', 'purchases_24_28',\n",
    "    'purchases_29_33', 'purchases_34_39', 'purchases_40', 'purchases_male', 'purchases_female', 'views', 'views_18',\n",
    "    'views_19_23', 'views_24_28', 'views_29_33', 'views_34_39', 'views_40', 'views_male', 'views_female', 'date',\n",
    "    'review', 'review_ID', 'grade', 'size', 'sex', 'height', 'weight', 'helpful', 'style_like', 'reviewtag_size',\n",
    "    'reviewtag_brightness', 'reviewtag_color', 'reviewtag_thickness', 'reviewtag_warmth', 'reviewtag_weight',\n",
    "    'reviewtag_delivery', 'reviewtag_packaging'\n",
    "]\n",
    "\n",
    "df = df[desired_order]\n",
    "\n",
    "# 데이터프레임을 CSV 파일로 저장\n",
    "df.to_csv('musinsa_crawling_dataset\\musinsa_crawling_columns_preprocessing_dataset_f.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### null 값 -> fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1156\\317276008.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['subcategory'].fillna('아울렛상품', inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1156\\317276008.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['product_tag'].fillna('태그없음', inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1156\\317276008.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviewtag_size'].fillna('태그없음', inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1156\\317276008.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviewtag_brightness'].fillna('태그없음', inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1156\\317276008.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviewtag_color'].fillna('태그없음', inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1156\\317276008.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviewtag_thickness'].fillna('태그없음', inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1156\\317276008.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviewtag_warmth'].fillna('태그없음', inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1156\\317276008.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviewtag_weight'].fillna('태그없음', inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1156\\317276008.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviewtag_delivery'].fillna('태그없음', inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1156\\317276008.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviewtag_packaging'].fillna('태그없음', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null 값이 있는 'sex' 컬럼의 행 개수: 0\n",
      "Null 값이 있는 'height' 컬럼의 행 개수: 0\n",
      "Null 값이 있는 'weight' 컬럼의 행 개수: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('musinsa_crawling_dataset/musinsa_crawling_columns_preprocessing_dataset_f.csv')\n",
    "\n",
    "# 'subcategory' 컬럼의 null 값을 '아울렛상품'으로 대체\n",
    "df['subcategory'].fillna('아울렛상품', inplace=True)\n",
    "\n",
    "# 'product_tag' 컬럼의 null 값을 '태그없음'으로 대체\n",
    "df['product_tag'].fillna('태그없음', inplace=True)\n",
    "\n",
    "# 'reviewtag' 컬럼의 null 값을 '태그없음'으로 대체\n",
    "df['reviewtag_size'].fillna('태그없음', inplace=True)\n",
    "df['reviewtag_brightness'].fillna('태그없음', inplace=True)\n",
    "df['reviewtag_color'].fillna('태그없음', inplace=True)\n",
    "df['reviewtag_thickness'].fillna('태그없음', inplace=True)\n",
    "df['reviewtag_warmth'].fillna('태그없음', inplace=True)\n",
    "df['reviewtag_weight'].fillna('태그없음', inplace=True)\n",
    "df['reviewtag_delivery'].fillna('태그없음', inplace=True)\n",
    "df['reviewtag_packaging'].fillna('태그없음', inplace=True)\n",
    "\n",
    "# 'sex', 'height', 'weight' 컬럼에서 null 값을 가진 행 삭제\n",
    "df.dropna(subset=['sex', 'height', 'weight'], inplace=True)\n",
    "\n",
    "\n",
    "# 변경된 데이터프레임을 새로운 CSV 파일로 저장\n",
    "df.to_csv('musinsa_crawling_dataset/musinsa_crawling_columns_preprocessing_dataset_f.csv', index=False)\n",
    "\n",
    "# 'sex', 'height', 'weight' 컬럼에서 null 값이 있는 행의 개수 출력 (삭제 후 확인용)\n",
    "null_sex_count = df['sex'].isnull().sum()\n",
    "null_height_count = df['height'].isnull().sum()\n",
    "null_weight_count = df['weight'].isnull().sum()\n",
    "\n",
    "print(f\"Null 값이 있는 'sex' 컬럼의 행 개수: {null_sex_count}\")\n",
    "print(f\"Null 값이 있는 'height' 컬럼의 행 개수: {null_height_count}\")\n",
    "print(f\"Null 값이 있는 'weight' 컬럼의 행 개수: {null_weight_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하위카테고리 sum\n",
    "1. 상의\n",
    "   1. 긴소매 티셔츠 -> 긴소매 티셔츠\n",
    "   2. 맨투맨/스웨트, 니트/스웨트 -> 맨투맨/니트/스웨트\n",
    "   3. 반소매 티셔츠, 민소매 티셔츠, 피케/카라 티셔츠 -> 민소매/반소매/카라 티셔츠\n",
    "   4. 셔츠/블라우스 -> 셔츠/블라우스\n",
    "   5. 아울렛상품 -> 아울렛상품\n",
    "2. 바지\n",
    "   1. 기타 바지, 코튼 팬츠, 트래이닝/조거 팬츠 -> 기타 바지\n",
    "   2. 데님 팬츠 -> 데님 팬츠\n",
    "   3. 숏 팬츠 -> 숏 팬츠\n",
    "   4. 슈트 팬츠/슬랙스\n",
    "   5. 아울렛상품\n",
    "3. 아우터\n",
    "   1. 겨울 싱글 코트, 겨울 기타 코트 -> 겨울 코트\n",
    "   2. 후드 집업 -> 후드 집업\n",
    "   3. 숏패딩/헤비 아우터 -> 숏패딩/헤비 아우터\n",
    "   4. 슈트/ 블레이저 재킷\n",
    "   5. 기타 아우터, 플리스/뽀글이 -> 플리스/뽀글이/기타 아우터\n",
    "   6. 블루종/ MA-1, 트러커 재킷 -> 블루종/트러커 재킷\n",
    "   7. 나일론/ 코치 재킷, 아노락 재킷-> 나일론/코치, 아노락 재킷\n",
    "   8. 베스트, 카디건 -> 베스트/카디건\n",
    "   9. 아울렛상품 -> 아울렛상품"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index  brand category     subcategory  \\\n",
      "0          1  에잇세컨즈       상의  민소매/반소매/카라 티셔츠   \n",
      "1          2  에잇세컨즈       상의  민소매/반소매/카라 티셔츠   \n",
      "2          3  에잇세컨즈       상의  민소매/반소매/카라 티셔츠   \n",
      "3          4  에잇세컨즈       상의  민소매/반소매/카라 티셔츠   \n",
      "4          5  에잇세컨즈       상의  민소매/반소매/카라 티셔츠   \n",
      "...      ...    ...      ...             ...   \n",
      "25880  25881     탑텐      아우터     슈트/ 블레이저 재킷   \n",
      "25881  25882     탑텐      아우터     슈트/ 블레이저 재킷   \n",
      "25882  25883     탑텐      아우터     슈트/ 블레이저 재킷   \n",
      "25883  25884     탑텐      아우터     슈트/ 블레이저 재킷   \n",
      "25884  25885     탑텐      아우터     슈트/ 블레이저 재킷   \n",
      "\n",
      "                                         product     product_ID  product_like  \\\n",
      "0              베이직 라운드넥 반소매 티셔츠 화이트 (324242LY11)  product_00071          1845   \n",
      "1              베이직 라운드넥 반소매 티셔츠 화이트 (324242LY11)  product_00071          1845   \n",
      "2              베이직 라운드넥 반소매 티셔츠 화이트 (324242LY11)  product_00071          1845   \n",
      "3              베이직 라운드넥 반소매 티셔츠 화이트 (324242LY11)  product_00071          1845   \n",
      "4              베이직 라운드넥 반소매 티셔츠 화이트 (324242LY11)  product_00071          1845   \n",
      "...                                          ...            ...           ...   \n",
      "25880     여성) 쿨터치 재킷 (SET MSD2PP2502)_MSD2KG2502  product_00097           307   \n",
      "25881  남성) 쿨터치 싱글 재킷 (SET MSD2PP1501)_MSD2KG1501  product_00047            97   \n",
      "25882  남성) 쿨터치 싱글 재킷 (SET MSD2PP1501)_MSD2KG1501  product_00047            97   \n",
      "25883  남성) 쿨터치 싱글 재킷 (SET MSD2PP1501)_MSD2KG1501  product_00047            97   \n",
      "25884  남성) 쿨터치 싱글 재킷 (SET MSD2PP1501)_MSD2KG1501  product_00047            97   \n",
      "\n",
      "       product_price price_range product_tag  ... helpful  style_like  \\\n",
      "0              14900      1~2만원대        태그없음  ...       0           0   \n",
      "1              14900      1~2만원대        태그없음  ...       0           0   \n",
      "2              14900      1~2만원대        태그없음  ...       0           0   \n",
      "3              14900      1~2만원대        태그없음  ...       0           0   \n",
      "4              14900      1~2만원대        태그없음  ...       0           0   \n",
      "...              ...         ...         ...  ...     ...         ...   \n",
      "25880          25900          기타        태그없음  ...       0           0   \n",
      "25881          25900          기타        태그없음  ...       0           0   \n",
      "25882          25900          기타        태그없음  ...       0           0   \n",
      "25883          25900          기타        태그없음  ...       0           0   \n",
      "25884          25900          기타        태그없음  ...       0           0   \n",
      "\n",
      "       reviewtag_size  reviewtag_brightness  reviewtag_color  \\\n",
      "0           사이즈 보통이에요                밝기 밝아요          색감 선명해요   \n",
      "1           사이즈 보통이에요              밝기 보통이에요         색감 보통이에요   \n",
      "2           사이즈 보통이에요              밝기 보통이에요         색감 보통이에요   \n",
      "3           사이즈 보통이에요              밝기 보통이에요         색감 보통이에요   \n",
      "4           사이즈 보통이에요              밝기 보통이에요         색감 보통이에요   \n",
      "...               ...                   ...              ...   \n",
      "25880       사이즈 보통이에요              밝기 보통이에요         색감 보통이에요   \n",
      "25881       사이즈 보통이에요                밝기 밝아요         색감 보통이에요   \n",
      "25882       사이즈 보통이에요              밝기 보통이에요          색감 선명해요   \n",
      "25883       사이즈 보통이에요              밝기 보통이에요         색감 보통이에요   \n",
      "25884       사이즈 보통이에요              밝기 보통이에요         색감 보통이에요   \n",
      "\n",
      "       reviewtag_thickness  reviewtag_warmth  reviewtag_weight  \\\n",
      "0                두께감 보통이에요              태그없음              태그없음   \n",
      "1                두께감 보통이에요              태그없음              태그없음   \n",
      "2                  두께감 얇아요              태그없음              태그없음   \n",
      "3                  두께감 얇아요              태그없음              태그없음   \n",
      "4                두께감 보통이에요              태그없음              태그없음   \n",
      "...                    ...               ...               ...   \n",
      "25880              두께감 얇아요              태그없음              태그없음   \n",
      "25881              두께감 얇아요              태그없음              태그없음   \n",
      "25882              두께감 얇아요              태그없음              태그없음   \n",
      "25883            두께감 보통이에요              태그없음              태그없음   \n",
      "25884            두께감 보통이에요              태그없음              태그없음   \n",
      "\n",
      "       reviewtag_delivery  reviewtag_packaging  \n",
      "0                  배송 빨라요              포장 꼼꼼해요  \n",
      "1                  배송 빨라요              포장 꼼꼼해요  \n",
      "2                  배송 빨라요              포장 꼼꼼해요  \n",
      "3                  배송 빨라요              포장 꼼꼼해요  \n",
      "4                  배송 빨라요              포장 꼼꼼해요  \n",
      "...                   ...                  ...  \n",
      "25880              배송 빨라요              포장 꼼꼼해요  \n",
      "25881              배송 빨라요              포장 아쉬워요  \n",
      "25882              배송 빨라요              포장 꼼꼼해요  \n",
      "25883              배송 빨라요              포장 꼼꼼해요  \n",
      "25884              배송 빨라요              포장 꼼꼼해요  \n",
      "\n",
      "[25878 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 하위 카테고리 매핑 정의\n",
    "subcategory_mapping = {\n",
    "    '긴소매 티셔츠': '긴소매 티셔츠',\n",
    "    '맨투맨/ 스웨트': '맨투맨/니트/스웨트',\n",
    "    '니트/스웨터': '맨투맨/니트/스웨트',\n",
    "    '반소매 티셔츠': '민소매/반소매/카라 티셔츠',\n",
    "    '민소매 티셔츠': '민소매/반소매/카라 티셔츠',\n",
    "    '피케/카라 티셔츠': '민소매/반소매/카라 티셔츠',\n",
    "    '셔츠/블라우스': '셔츠/블라우스',\n",
    "    '아울렛상품': '아울렛상품',\n",
    "    '기타 바지': '기타 바지',\n",
    "    '코튼 팬츠': '기타 바지',\n",
    "    '트레이닝/조거 팬츠': '기타 바지',\n",
    "    '트래이닝/조거 팬츠': '기타 바지',\n",
    "    '데님 팬츠': '데님 팬츠',\n",
    "    '숏 팬츠': '숏 팬츠',\n",
    "    '슈트 팬츠/슬랙스': '슈트 팬츠/슬랙스',\n",
    "    '겨울 싱글 코트': '겨울 코트',\n",
    "    '겨울 기타 코트': '겨울 코트',\n",
    "    '후드 집업': '후드 집업',\n",
    "    '숏패딩/헤비 아우터': '숏패딩/헤비 아우터',\n",
    "    '슈트/ 블레이저 재킷': '슈트/ 블레이저 재킷',\n",
    "    '기타 아우터': '플리스/뽀글이/기타 아우터',\n",
    "    '플리스/뽀글이': '플리스/뽀글이/기타 아우터',\n",
    "    '블루종/ MA-1': '블루종/트러커 재킷',\n",
    "    '트러커 재킷': '블루종/트러커 재킷',\n",
    "    '나일론/ 코치 재킷': '나일론/코치, 아노락 재킷',\n",
    "    '아노락 재킷': '나일론/코치, 아노락 재킷',\n",
    "    '베스트': '베스트/카디건',\n",
    "    '카디건': '베스트/카디건'\n",
    "}\n",
    "\n",
    "# subcategory 컬럼의 값을 매핑\n",
    "df['subcategory'] = df['subcategory'].map(subcategory_mapping)\n",
    "\n",
    "# 결과 확인\n",
    "print(df)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df.to_csv('musinsa_crawling_dataset\\musinsa_crawling_columns_preprocessing_dataset_f.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic 컬럼 추가 -> 빈상태로 추가 추후 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'topic' 컬럼 추가 (값이 없는 상태로 설정)\n",
    "df['topic'] = pd.NA\n",
    "\n",
    "# 변경된 데이터프레임을 새로운 CSV 파일로 저장\n",
    "df.to_csv('musinsa_crawling_dataset\\musinsa_crawling_columns_preprocessing_dataset_f.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터프레임 info 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25878 entries, 0 to 25877\n",
      "Data columns (total 48 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   index                    25878 non-null  int64  \n",
      " 1   brand                    25878 non-null  object \n",
      " 2   category                 25878 non-null  object \n",
      " 3   subcategory              25878 non-null  object \n",
      " 4   product                  25878 non-null  object \n",
      " 5   product_ID               25878 non-null  object \n",
      " 6   product_like             25878 non-null  int64  \n",
      " 7   product_price            25878 non-null  int64  \n",
      " 8   price_range              25878 non-null  object \n",
      " 9   product_tag              25878 non-null  object \n",
      " 10  cumulative_sales_volume  25878 non-null  object \n",
      " 11  purchases                25878 non-null  int64  \n",
      " 12  purchases_18             25878 non-null  int64  \n",
      " 13  purchases_19_23          25878 non-null  int64  \n",
      " 14  purchases_24_28          25878 non-null  int64  \n",
      " 15  purchases_29_33          25878 non-null  int64  \n",
      " 16  purchases_34_39          25878 non-null  int64  \n",
      " 17  purchases_40             25878 non-null  int64  \n",
      " 18  purchases_male           25878 non-null  int64  \n",
      " 19  purchases_female         25878 non-null  int64  \n",
      " 20  views                    25878 non-null  int64  \n",
      " 21  views_18                 25878 non-null  int64  \n",
      " 22  views_19_23              25878 non-null  int64  \n",
      " 23  views_24_28              25878 non-null  int64  \n",
      " 24  views_29_33              25878 non-null  int64  \n",
      " 25  views_34_39              25878 non-null  int64  \n",
      " 26  views_40                 25878 non-null  int64  \n",
      " 27  views_male               25878 non-null  int64  \n",
      " 28  views_female             25878 non-null  int64  \n",
      " 29  date                     25878 non-null  int64  \n",
      " 30  review                   25878 non-null  object \n",
      " 31  review_ID                25878 non-null  object \n",
      " 32  grade                    25878 non-null  int64  \n",
      " 33  size                     25878 non-null  object \n",
      " 34  sex                      25878 non-null  float64\n",
      " 35  height                   25878 non-null  float64\n",
      " 36  weight                   25878 non-null  float64\n",
      " 37  helpful                  25878 non-null  int64  \n",
      " 38  style_like               25878 non-null  int64  \n",
      " 39  reviewtag_size           25878 non-null  object \n",
      " 40  reviewtag_brightness     25878 non-null  object \n",
      " 41  reviewtag_color          25878 non-null  object \n",
      " 42  reviewtag_thickness      25878 non-null  object \n",
      " 43  reviewtag_warmth         25878 non-null  object \n",
      " 44  reviewtag_weight         25878 non-null  object \n",
      " 45  reviewtag_delivery       25878 non-null  object \n",
      " 46  reviewtag_packaging      25878 non-null  object \n",
      " 47  topic                    0 non-null      float64\n",
      "dtypes: float64(4), int64(25), object(19)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('musinsa_crawling_dataset/musinsa_crawling_columns_preprocessing_dataset_f.csv')\n",
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
